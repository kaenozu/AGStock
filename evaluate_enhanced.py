"""
Enhanced Prediction Evaluation with Comprehensive Features
Tests the impact of 50+ advanced features on prediction accuracy.
"""

import logging
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split

from src.data_loader import fetch_stock_data, fetch_external_data
from src.features.comprehensive_features import ComprehensiveFeatureGenerator
from src.ensemble.stacking import create_default_stacking_ensemble
from src.optimization.hyperparameter_tuner import HyperparameterOptimizer

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


def calculate_directional_accuracy(y_true: np.ndarray, y_pred: np.ndarray) -> float:
    """Calculate directional accuracy."""
    correct = sum((y_true > 0) == (y_pred > 0))
    return correct / len(y_true)


def main():
    logger.info("="*70)
    logger.info("åŒ…æ‹¬çš„ç‰¹å¾´é‡ã«ã‚ˆã‚‹äºˆæ¸¬ç²¾åº¦è©•ä¾¡")
    logger.info("="*70)
    
    # 1. ãƒ‡ãƒ¼ã‚¿å–å¾—
    logger.info("\nğŸ“Š ãƒ‡ãƒ¼ã‚¿å–å¾—ä¸­...")
    ticker = '7203.T'  # ãƒˆãƒ¨ã‚¿
    data = fetch_stock_data([ticker], period='2y', interval='1d')
    df = data.get(ticker)
    
    if df is None or df.empty:
        logger.error(f"ãƒ‡ãƒ¼ã‚¿å–å¾—å¤±æ•—: {ticker}")
        return
    
    # å¤–éƒ¨ãƒ‡ãƒ¼ã‚¿å–å¾—
    external_data = fetch_external_data(period='2y')
    
    logger.info(f"âœ… ãƒ‡ãƒ¼ã‚¿å–å¾—å®Œäº†: {ticker} ({len(df)} rows)")
    
    # 2. åŒ…æ‹¬çš„ç‰¹å¾´é‡ç”Ÿæˆ
    logger.info("\nğŸ”§ åŒ…æ‹¬çš„ç‰¹å¾´é‡ç”Ÿæˆä¸­...")
    feature_gen = ComprehensiveFeatureGenerator()
    df_features = feature_gen.generate_all_features(df, external_data)
    
    # Target
    df_features['target'] = df_features['Close'].pct_change().shift(-1)
    df_features = df_features.dropna()
    
    # Feature columns (exclude OHLCV and target)
    exclude_cols = ['Open', 'High', 'Low', 'Close', 'Volume', 'target']
    feature_cols = [col for col in df_features.columns if col not in exclude_cols]
    
    logger.info(f"âœ… ç‰¹å¾´é‡ç”Ÿæˆå®Œäº†: {len(feature_cols)} features")
    logger.info(f"   ç‰¹å¾´é‡ä¾‹: {feature_cols[:10]}")
    
    # 3. Train/Test split
    X = df_features[feature_cols]
    y = df_features['target']
    
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, shuffle=False
    )
    
    logger.info(f"\nğŸ“Š ãƒ‡ãƒ¼ã‚¿åˆ†å‰²:")
    logger.info(f"   Train: {len(X_train)} samples")
    logger.info(f"   Test: {len(X_test)} samples")
    
    # 4. ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–
    logger.info("\nğŸ¯ ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–ä¸­...")
    optimizer = HyperparameterOptimizer(n_trials=30)
    best_params = optimizer.optimize_lgbm(X_train, y_train)
    
    # 5. æœ€é©åŒ–ãƒ¢ãƒ‡ãƒ«ã§è©•ä¾¡
    from lightgbm import LGBMRegressor
    model = LGBMRegressor(**best_params, random_state=42)
    model.fit(X_train, y_train)
    
    y_pred = model.predict(X_test)
    
    # 6. è©•ä¾¡
    directional_acc = calculate_directional_accuracy(y_test.values, y_pred)
    mae = np.mean(np.abs(y_test - y_pred))
    rmse = np.sqrt(np.mean((y_test - y_pred) ** 2))
    
    logger.info("\n" + "="*70)
    logger.info("ğŸ“Š è©•ä¾¡çµæœï¼ˆåŒ…æ‹¬çš„ç‰¹å¾´é‡ï¼‰")
    logger.info("="*70)
    logger.info(f"æ–¹å‘æ€§ç²¾åº¦: {directional_acc:.2%}")
    logger.info(f"MAE: {mae:.6f}")
    logger.info(f"RMSE: {rmse:.6f}")
    
    # 7. ç‰¹å¾´é‡é‡è¦åº¦
    logger.info("\n" + "="*70)
    logger.info("ğŸ“ˆ ç‰¹å¾´é‡é‡è¦åº¦ Top 20")
    logger.info("="*70)
    
    feature_importance = pd.DataFrame({
        'feature': feature_cols,
        'importance': model.feature_importances_
    }).sort_values('importance', ascending=False)
    
    print("\n", feature_importance.head(20).to_string(index=False))
    
    # 8. ã‚¹ã‚¿ãƒƒã‚­ãƒ³ã‚°ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã§è©•ä¾¡
    logger.info("\nğŸš€ ã‚¹ã‚¿ãƒƒã‚­ãƒ³ã‚°ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«è©•ä¾¡...")
    stacking = create_default_stacking_ensemble()
    stacking.fit(X_train, y_train)
    
    y_pred_stacking = stacking.predict(X_test)
    directional_acc_stacking = calculate_directional_accuracy(y_test.values, y_pred_stacking)
    
    logger.info(f"\nã‚¹ã‚¿ãƒƒã‚­ãƒ³ã‚°æ–¹å‘æ€§ç²¾åº¦: {directional_acc_stacking:.2%}")
    
    # 9. æ¯”è¼ƒ
    logger.info("\n" + "="*70)
    logger.info("ğŸ“Š æ”¹å–„åŠ¹æœ")
    logger.info("="*70)
    logger.info(f"åŸºæœ¬ç‰¹å¾´é‡ï¼ˆ4å€‹ï¼‰: 56.38%")
    logger.info(f"åŒ…æ‹¬çš„ç‰¹å¾´é‡ï¼ˆ{len(feature_cols)}å€‹ï¼‰: {directional_acc:.2%}")
    logger.info(f"æ”¹å–„: {(directional_acc - 0.5638)*100:+.1f}%pt")
    
    logger.info("\n" + "="*70)
    logger.info("âœ… è©•ä¾¡å®Œäº†")
    logger.info("="*70)


if __name__ == "__main__":
    main()
