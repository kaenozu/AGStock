"""
Long-term Data Evaluation
Evaluates prediction models using 26 years of historical data.
"""

import logging
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from lightgbm import LGBMRegressor

from src.data_loader import fetch_stock_data, fetch_external_data
from src.features.comprehensive_features import ComprehensiveFeatureGenerator
from src.features.feature_selector import SHAPFeatureSelector
from src.ensemble.stacking import create_default_stacking_ensemble

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


def calculate_directional_accuracy(y_true: np.ndarray, y_pred: np.ndarray) -> float:
    """Calculate directional accuracy."""
    correct = sum((y_true > 0) == (y_pred > 0))
    return correct / len(y_true)


def calculate_sharpe_ratio(returns: np.ndarray, risk_free_rate: float = 0.0) -> float:
    """Calculate Sharpe ratio."""
    excess_returns = returns - risk_free_rate
    if np.std(excess_returns) == 0:
        return 0
    return np.mean(excess_returns) / np.std(excess_returns) * np.sqrt(252)


def main():
    logger.info("="*70)
    logger.info("26å¹´åˆ†ãƒ‡ãƒ¼ã‚¿ã«ã‚ˆã‚‹äºˆæ¸¬ç²¾åº¦è©•ä¾¡")
    logger.info("="*70)
    
    # 1. æœ€å¤§æœŸé–“ã®ãƒ‡ãƒ¼ã‚¿å–å¾—
    logger.info("\nğŸ“Š ãƒ‡ãƒ¼ã‚¿å–å¾—ä¸­ï¼ˆæœ€å¤§æœŸé–“ï¼‰...")
    ticker = '7203.T'
    data = fetch_stock_data([ticker], period='max', interval='1d')
    df = data.get(ticker)
    
    if df is None or df.empty:
        logger.error(f"ãƒ‡ãƒ¼ã‚¿å–å¾—å¤±æ•—: {ticker}")
        return
    
    logger.info(f"âœ… ãƒ‡ãƒ¼ã‚¿å–å¾—å®Œäº†: {ticker}")
    logger.info(f"   æœŸé–“: {df.index[0]} ï½ {df.index[-1]}")
    logger.info(f"   ãƒ‡ãƒ¼ã‚¿é‡: {len(df):,} ãƒ¬ã‚³ãƒ¼ãƒ‰")
    logger.info(f"   ç´„ {(df.index[-1] - df.index[0]).days / 365:.1f} å¹´åˆ†")
    
    # 2. å¤–éƒ¨ãƒ‡ãƒ¼ã‚¿å–å¾—
    external_data = fetch_external_data(period='max')
    
    # 3. åŒ…æ‹¬çš„ç‰¹å¾´é‡ç”Ÿæˆ
    logger.info("\nğŸ”§ åŒ…æ‹¬çš„ç‰¹å¾´é‡ç”Ÿæˆä¸­...")
    feature_gen = ComprehensiveFeatureGenerator()
    df_features = feature_gen.generate_all_features(df, external_data)
    
    # Target
    df_features['target'] = df_features['Close'].pct_change().shift(-1)
    df_features = df_features.dropna()
    
    # Feature columns
    exclude_cols = ['Open', 'High', 'Low', 'Close', 'Volume', 'target']
    feature_cols = [col for col in df_features.columns if col not in exclude_cols]
    
    logger.info(f"âœ… ç‰¹å¾´é‡ç”Ÿæˆå®Œäº†: {len(feature_cols)} features")
    logger.info(f"   æœ‰åŠ¹ã‚µãƒ³ãƒ—ãƒ«æ•°: {len(df_features):,}")
    
    # 4. Train/Test split (80/20)
    X = df_features[feature_cols]
    y = df_features['target']
    
    # Time-series split (æœ€å¾Œã®20%ã‚’ãƒ†ã‚¹ãƒˆ)
    split_idx = int(len(X) * 0.8)
    X_train = X.iloc[:split_idx]
    X_test = X.iloc[split_idx:]
    y_train = y.iloc[:split_idx]
    y_test = y.iloc[split_idx:]
    
    logger.info(f"\nğŸ“Š ãƒ‡ãƒ¼ã‚¿åˆ†å‰²:")
    logger.info(f"   Train: {len(X_train):,} samples ({X_train.index[0]} ï½ {X_train.index[-1]})")
    logger.info(f"   Test:  {len(X_test):,} samples ({X_test.index[0]} ï½ {X_test.index[-1]})")
    
    # 5. åŸºæœ¬ãƒ¢ãƒ‡ãƒ«ï¼ˆå…¨ç‰¹å¾´é‡ï¼‰
    logger.info("\nğŸ¯ åŸºæœ¬ãƒ¢ãƒ‡ãƒ«è©•ä¾¡ï¼ˆå…¨ç‰¹å¾´é‡ï¼‰...")
    model_full = LGBMRegressor(
        n_estimators=300,
        learning_rate=0.03,
        max_depth=8,
        num_leaves=64,
        reg_alpha=0.5,
        reg_lambda=0.5,
        random_state=42
    )
    
    model_full.fit(X_train, y_train)
    y_pred_full = model_full.predict(X_test)
    
    acc_full = calculate_directional_accuracy(y_test.values, y_pred_full)
    sharpe_full = calculate_sharpe_ratio(y_pred_full)
    
    logger.info(f"æ–¹å‘æ€§ç²¾åº¦: {acc_full:.2%}")
    logger.info(f"ã‚·ãƒ£ãƒ¼ãƒ—ãƒ¬ã‚·ã‚ª: {sharpe_full:.2f}")
    
    # 6. SHAPç‰¹å¾´é‡é¸æŠ
    logger.info("\nğŸ¯ SHAPç‰¹å¾´é‡é¸æŠ...")
    selector = SHAPFeatureSelector(n_features=20)
    X_train_selected = selector.fit_transform(X_train, y_train)
    X_test_selected = selector.transform(X_test)
    
    logger.info(f"é¸æŠã•ã‚ŒãŸç‰¹å¾´é‡: {selector.selected_features[:10]}...")
    
    # 7. é¸æŠç‰¹å¾´é‡ãƒ¢ãƒ‡ãƒ«
    logger.info("\nğŸš€ é¸æŠç‰¹å¾´é‡ãƒ¢ãƒ‡ãƒ«è©•ä¾¡...")
    model_selected = LGBMRegressor(
        n_estimators=300,
        learning_rate=0.03,
        max_depth=8,
        num_leaves=64,
        reg_alpha=1.0,
        reg_lambda=1.0,
        random_state=42
    )
    
    model_selected.fit(X_train_selected, y_train)
    y_pred_selected = model_selected.predict(X_test_selected)
    
    acc_selected = calculate_directional_accuracy(y_test.values, y_pred_selected)
    sharpe_selected = calculate_sharpe_ratio(y_pred_selected)
    
    logger.info(f"æ–¹å‘æ€§ç²¾åº¦: {acc_selected:.2%}")
    logger.info(f"ã‚·ãƒ£ãƒ¼ãƒ—ãƒ¬ã‚·ã‚ª: {sharpe_selected:.2f}")
    
    # 8. ã‚¹ã‚¿ãƒƒã‚­ãƒ³ã‚°ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«
    logger.info("\nğŸ¯ ã‚¹ã‚¿ãƒƒã‚­ãƒ³ã‚°ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«è©•ä¾¡...")
    stacking = create_default_stacking_ensemble()
    stacking.fit(X_train_selected, y_train)
    
    y_pred_stacking = stacking.predict(X_test_selected)
    acc_stacking = calculate_directional_accuracy(y_test.values, y_pred_stacking)
    sharpe_stacking = calculate_sharpe_ratio(y_pred_stacking)
    
    logger.info(f"æ–¹å‘æ€§ç²¾åº¦: {acc_stacking:.2%}")
    logger.info(f"ã‚·ãƒ£ãƒ¼ãƒ—ãƒ¬ã‚·ã‚ª: {sharpe_stacking:.2f}")
    
    # 9. çµæœæ¯”è¼ƒ
    logger.info("\n" + "="*70)
    logger.info("ğŸ“Š æœ€çµ‚çµæœæ¯”è¼ƒ")
    logger.info("="*70)
    
    results = pd.DataFrame({
        'ãƒ¢ãƒ‡ãƒ«': [
            'ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ï¼ˆ2å¹´ã€4ç‰¹å¾´é‡ï¼‰',
            'å…¨ç‰¹å¾´é‡ï¼ˆ26å¹´ã€63ç‰¹å¾´é‡ï¼‰',
            'é¸æŠç‰¹å¾´é‡ï¼ˆ26å¹´ã€20ç‰¹å¾´é‡ï¼‰',
            'ã‚¹ã‚¿ãƒƒã‚­ãƒ³ã‚°ï¼ˆ26å¹´ã€20ç‰¹å¾´é‡ï¼‰'
        ],
        'ãƒ‡ãƒ¼ã‚¿é‡': ['487', f'{len(X_train):,}', f'{len(X_train):,}', f'{len(X_train):,}'],
        'æ–¹å‘æ€§ç²¾åº¦': ['56.38%', f'{acc_full:.2%}', f'{acc_selected:.2%}', f'{acc_stacking:.2%}'],
        'ã‚·ãƒ£ãƒ¼ãƒ—ãƒ¬ã‚·ã‚ª': ['-', f'{sharpe_full:.2f}', f'{sharpe_selected:.2f}', f'{sharpe_stacking:.2f}']
    })
    
    print("\n", results.to_string(index=False))
    
    # 10. æ”¹å–„ç‡
    baseline_acc = 0.5638
    improvement_full = (acc_full - baseline_acc) * 100
    improvement_selected = (acc_selected - baseline_acc) * 100
    improvement_stacking = (acc_stacking - baseline_acc) * 100
    
    logger.info("\n" + "="*70)
    logger.info("ğŸ“ˆ ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‹ã‚‰ã®æ”¹å–„")
    logger.info("="*70)
    logger.info(f"å…¨ç‰¹å¾´é‡:       {improvement_full:+.1f}%pt")
    logger.info(f"é¸æŠç‰¹å¾´é‡:     {improvement_selected:+.1f}%pt")
    logger.info(f"ã‚¹ã‚¿ãƒƒã‚­ãƒ³ã‚°:   {improvement_stacking:+.1f}%pt")
    
    # 11. ç‰¹å¾´é‡é‡è¦åº¦
    logger.info("\n" + "="*70)
    logger.info("ğŸ† é‡è¦ç‰¹å¾´é‡ Top 10")
    logger.info("="*70)
    
    importance_df = selector.get_feature_importance()
    print("\n", importance_df.head(10).to_string(index=False))
    
    logger.info("\n" + "="*70)
    logger.info("âœ… è©•ä¾¡å®Œäº†")
    logger.info("="*70)


if __name__ == "__main__":
    main()
